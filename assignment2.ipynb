{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1 Kai Foerster (ID: 214288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Choose one of the sessions, and retrieve it using R or Python.\n",
    "\n",
    "# URL of the XML data\n",
    "url = \"https://www.bundestag.de/resource/blob/968690/5d723616da1ea3ca054e8da604ff1004/20124-data.xml\"\n",
    "\n",
    "# Send a GET request to the server and store the response\n",
    "r = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 Using a scraper, get a list of all the elements.\n",
    "\n",
    "rede_elements = soup.find_all('rede')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Christian Lindner</td>\n",
       "      <td>Frau Präsidentin! Liebe Kolleginnen und Kolleg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Svenja Schulze</td>\n",
       "      <td>Sehr geehrte Frau Präsidentin, das freut uns a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mathias Middelberg</td>\n",
       "      <td>Frau Präsidentin, herzlichen Dank für das Wort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christian Lindner</td>\n",
       "      <td>Vielen Dank, Frau Präsidentin. – Lieber Herr K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mathias Middelberg</td>\n",
       "      <td>Auch wir finden den angebotsorientierten Ansat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Manfred Todtenhausen</td>\n",
       "      <td>Frau Präsidentin! Liebe Kolleginnen! Liebe Kol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Martina Stamm-Fibich</td>\n",
       "      <td>Sehr geehrte Frau Präsidentin! Liebe Kolleginn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Dirk Brandes</td>\n",
       "      <td>Vielen Dank, Frau Präsidentin, dass Sie die Ku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Daniela Ludwig</td>\n",
       "      <td>Frau Präsidentin! Liebe Kolleginnen und Kolleg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Axel Echeverria</td>\n",
       "      <td>Frau Präsidentin! Liebe Kolleginnen und Kolleg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name                                             Speech\n",
       "0       Christian Lindner  Frau Präsidentin! Liebe Kolleginnen und Kolleg...\n",
       "1          Svenja Schulze  Sehr geehrte Frau Präsidentin, das freut uns a...\n",
       "2      Mathias Middelberg  Frau Präsidentin, herzlichen Dank für das Wort...\n",
       "3       Christian Lindner  Vielen Dank, Frau Präsidentin. – Lieber Herr K...\n",
       "4      Mathias Middelberg  Auch wir finden den angebotsorientierten Ansat...\n",
       "..                    ...                                                ...\n",
       "159  Manfred Todtenhausen  Frau Präsidentin! Liebe Kolleginnen! Liebe Kol...\n",
       "160  Martina Stamm-Fibich  Sehr geehrte Frau Präsidentin! Liebe Kolleginn...\n",
       "161          Dirk Brandes  Vielen Dank, Frau Präsidentin, dass Sie die Ku...\n",
       "162        Daniela Ludwig  Frau Präsidentin! Liebe Kolleginnen und Kolleg...\n",
       "163       Axel Echeverria  Frau Präsidentin! Liebe Kolleginnen und Kolleg...\n",
       "\n",
       "[164 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3 For each element, get the name of the speaker, and a single string containing everything that they said. \n",
    "# Put this into a dataframe.\n",
    "\n",
    "# Initialize a list to store the extracted info\n",
    "data = []\n",
    "\n",
    "for rede in rede_elements:\n",
    "    # Extract the paragraph describing the speaker\n",
    "    vorname_element = rede.select('vorname')\n",
    "    nachname_element = rede.select('nachname')\n",
    "    \n",
    "    # Check if vorname and nachname elements are not empty, and extract text from them\n",
    "    vorname = vorname_element[0].text if vorname_element else \"\"\n",
    "    nachname = nachname_element[0].text if nachname_element else \"\"\n",
    "    \n",
    "    # Extract the speech paragraphs with klasse=\"J\", \"J_1\", or \"O\"\n",
    "    speech_paragraphs = rede.select('p', class_=['J', 'J_1', 'O'])\n",
    "    \n",
    "    # Combine all speech paragraphs into one string, skipping the first paragraph if there are more than one\n",
    "    speech_text = ' '.join([p.get_text(strip=True) for p in speech_paragraphs[1:]]) \n",
    "    \n",
    "    # Append the extracted information to the data list\n",
    "    data.append({\n",
    "        \"Name\": vorname + \" \" + nachname,\n",
    "        \"Speech\": speech_text\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Name  count\n",
      "14  Christian Lindner     27\n"
     ]
    }
   ],
   "source": [
    "#2.1 Choose a politician, and print the number of speeches they made in this session\n",
    "\n",
    "# Group by 'Name', count the occurrences, and reset the index\n",
    "grouped_df = df.groupby('Name').size().reset_index(name='count')\n",
    "\n",
    "# Sort the DataFrame based on the 'count' column in descending order\n",
    "sorted_df = grouped_df.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Filter the rows where 'Name' is 'Christian Lindner'\n",
    "filtered_df = sorted_df[sorted_df['Name'] == 'Christian Lindner']\n",
    "\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frau Präsidentin! Liebe Kolleginnen und Kollegen! Ich will mich zunächst bei der Innenministerin, Nancy Faeser, bedanken, dass sie in der vergangenen Woche kurzfristig eingesprungen ist, als ich positiv war, eine Covid-Infektion hatte. Ich will drei Punkte nennen. Erster Punkt. Die wirtschaftliche Entwicklung in unserem Land ist unbefriedigend. Hierbei sind zum einen konjunkturelle Belastungsfaktoren, zum anderen aber auch strukturelle Defizite unserer Wettbewerbsfähigkeit, die wir seit vielen Jahren kennen, zu nennen. Die Bundesregierung geht diese entschlossen an, von A wie „Arbeitskräfte“ bis P wie „Planungs- und Genehmigungsverfahren“, die wir beschleunigen wollen. In meinem Geschäftsbereich kommen zwei wichtige Gesetzgebungsvorhaben hinzu: zum einen das Wachstumschancengesetz, mit dem wir Forschungsförderung, Investitionen und Eigenkapitalbasis stärken, sowie das Zukunftsfinanzierungsgesetz, mit dem wir den Kapitalmarktzugang insbesondere für junge und innovative Unternehmen verbessern und mit dem wir über bessere Rahmenbedingungen bei der Mitarbeiterkapitalbeteiligung die Gewinnung von Talenten in diesem Bereich unserer Wirtschaft verbessern. Zum Zweiten. Wir haben unverändert eine zu hohe Inflation. Die Europäische Zentralbank hat die Zinsen erhöht, um die Inflation zu bekämpfen. Es wäre falsch bzw. ökonomisch unverantwortbar, würde der Staat die Inflation dadurch anheizen, dass er jetzt noch Ausgabeprogramme – schuldenfinanziert – auf den Weg bringt. Das macht die Bundesregierung nicht. Sie wissen: Wir halten uns an die Schuldenbremse und erreichen bereits in diesem Jahr ein Staatsdefizit von unter 3 Prozent. Bereits in diesem Jahr sinkt die Staatsschuldenquote, und zwar unter Berücksichtigung des Kernhaushalts sowie aller Sondervermögen. Am Ende des Finanzplanungszeitraums sind wir bereits auf dem Weg zum Vorkrisenniveau. Die fiskalische Trendwende ist trotz Rekordinvestitionen gelungen. Zum Dritten. Meine Damen und Herren, liebe Kolleginnen und Kollegen, wir sehen sehr hohe Migrationszahlen in Europa und auch in Deutschland. Sorge bereitet uns insbesondere die Schlepperkriminalität. Die Bundesinnenministerin hat deshalb zusätzliche flexible Kontrollen im grenznahen Raum angekündigt. Dabei wird der Grundsatz der Freizügigkeit beachtet, dabei wird auch das Wirtschaftsleben nicht beeinträchtigt werden. Aber wir müssen dafür Sorge tragen, dass die Schlepperkriminalität nicht in dieser Weise weiter bestehen kann. Ich habe deshalb entschieden, dass der Zoll die Kräfte des Bundesinnenministeriums unterstützt. Bis zu 500 Vollzugsbeamtinnen und Vollzugsbeamte des Zolls, insbesondere aus dem Bereich der Kontrolleinheiten Verkehrswege, werden deshalb zur Verfügung stehen, um die Durchsetzung dieser stationären Kontrollen sicherzustellen. Nach 2015 hat Deutschland streckenweise die Kontrolle über den Zugang in dieses Land verloren. Dieser Zustand darf nicht fortgesetzt werden. Entschuldigung, Frau Schulze, ich war kurz unaufmerksam und habe Ihnen nicht sofort das Wort erteilt, weil ich mich so gefreut habe, dass Herr Lindner wieder da ist. Das Wort für den zweiten einleitenden Bericht hat nun die Bundesministerin für wirtschaftliche Zusammenarbeit und Entwicklung, Frau Svenja Schulze.\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Print the content of the first speech by the politician you choose.\n",
    "\n",
    "# Filter rows where 'Name' is 'Svenja Schulze'\n",
    "lindner_speech = df[df['Name'] == 'Christian Lindner']\n",
    "\n",
    "# Access the first row and the second column\n",
    "element = lindner_speech.iloc[0, 1]  # Remember, Python uses zero-based indexing. lindner_speech['Speech'].iloc[0] is an alternative\n",
    "\n",
    "print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kaius\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kaius\\OneDrive - Hertie School\\MSc Data Science for Public Policy\\Semester_3\\Text as Data\\assignments\\TaD-programming-excercises\\assignment2.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaius/OneDrive%20-%20Hertie%20School/MSc%20Data%20Science%20for%20Public%20Policy/Semester_3/Text%20as%20Data/assignments/TaD-programming-excercises/assignment2.ipynb#X42sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Initialize TfidfVectorizer with German stop words and without tokenization of words with punctuation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaius/OneDrive%20-%20Hertie%20School/MSc%20Data%20Science%20for%20Public%20Policy/Semester_3/Text%20as%20Data/assignments/TaD-programming-excercises/assignment2.ipynb#X42sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m vectorizer \u001b[39m=\u001b[39m TfidfVectorizer(stop_words\u001b[39m=\u001b[39mgerman_stop_words, token_pattern\u001b[39m=\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kaius/OneDrive%20-%20Hertie%20School/MSc%20Data%20Science%20for%20Public%20Policy/Semester_3/Text%20as%20Data/assignments/TaD-programming-excercises/assignment2.ipynb#X42sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m dfm \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39;49mfit_transform(all_speeches)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaius/OneDrive%20-%20Hertie%20School/MSc%20Data%20Science%20for%20Public%20Policy/Semester_3/Text%20as%20Data/assignments/TaD-programming-excercises/assignment2.ipynb#X42sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m vocab \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mget_feature_names_out()\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2139\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params()\n\u001b[0;32m   2133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf \u001b[39m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2134\u001b[0m     norm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm,\n\u001b[0;32m   2135\u001b[0m     use_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_idf,\n\u001b[0;32m   2136\u001b[0m     smooth_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmooth_idf,\n\u001b[0;32m   2137\u001b[0m     sublinear_tf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msublinear_tf,\n\u001b[0;32m   2138\u001b[0m )\n\u001b[1;32m-> 2139\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[0;32m   2140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m   2141\u001b[0m \u001b[39m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2142\u001b[0m \u001b[39m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1367\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1363\u001b[0m \u001b[39m# We intentionally don't call the transform method to make\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m \u001b[39m# fit_transform overridable without unwanted side effects in\u001b[39;00m\n\u001b[0;32m   1365\u001b[0m \u001b[39m# TfidfVectorizer.\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(raw_documents, \u001b[39mstr\u001b[39m):\n\u001b[1;32m-> 1367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1368\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIterable over raw text documents expected, string object received.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m     )\n\u001b[0;32m   1371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_ngram_range()\n\u001b[0;32m   1372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_for_unused_params()\n",
      "\u001b[1;31mValueError\u001b[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#lindner_speeches = lindner_speech['Speech']\n",
    "#all_speeches = ' '.join([p for p in lindner_speeches])\n",
    "all_speeches = element\n",
    "\n",
    "# Load German stop words\n",
    "german_stop_words = list(stopwords.words('german'))\n",
    "\n",
    "# Initialize TfidfVectorizer with German stop words and without tokenization of words with punctuation\n",
    "vectorizer = TfidfVectorizer(stop_words=german_stop_words, token_pattern=r'\\b\\w+\\b')\n",
    "dfm = vectorizer.fit_transform(all_speeches)\n",
    "vocab = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x0000027C0FF45090> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:126\u001b[0m, in \u001b[0;36mflush_figures\u001b[1;34m()\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m InlineBackend\u001b[39m.\u001b[39minstance()\u001b[39m.\u001b[39mclose_figures:\n\u001b[0;32m    124\u001b[0m     \u001b[39m# ignore the tracking, just draw and close all figures\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m         \u001b[39mreturn\u001b[39;00m show(\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    127\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    128\u001b[0m         \u001b[39m# safely show traceback if in IPython, else raise\u001b[39;00m\n\u001b[0;32m    129\u001b[0m         ip \u001b[39m=\u001b[39m get_ipython()\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[39mfor\u001b[39;00m figure_manager \u001b[39min\u001b[39;00m Gcf\u001b[39m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m---> 90\u001b[0m         display(\n\u001b[0;32m     91\u001b[0m             figure_manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mfigure,\n\u001b[0;32m     92\u001b[0m             metadata\u001b[39m=\u001b[39;49m_fetch_figure_metadata(figure_manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mfigure)\n\u001b[0;32m     93\u001b[0m         )\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     show\u001b[39m.\u001b[39m_to_draw \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[39m=\u001b[39mobj, metadata\u001b[39m=\u001b[39mmetadata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mformat\u001b[39;49m(obj, include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[0;32m    299\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[39m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\IPython\\core\\formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    177\u001b[0m md \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     data \u001b[39m=\u001b[39m formatter(obj)\n\u001b[0;32m    180\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     \u001b[39m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39m(extras \u001b[39m+\u001b[39m args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\IPython\\core\\formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 223\u001b[0m     r \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    224\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     \u001b[39m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_return(\u001b[39mNone\u001b[39;00m, args[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\IPython\\core\\formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[0;32m    341\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    342\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\IPython\\core\\pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 152\u001b[0m fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mprint_figure(bytes_io, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    153\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[0;32m    154\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\backend_bases.py:2158\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2155\u001b[0m     \u001b[39m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[0;32m   2156\u001b[0m     \u001b[39m# so that we can inject the orientation\u001b[39;00m\n\u001b[0;32m   2157\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mgetattr\u001b[39m(renderer, \u001b[39m\"\u001b[39m\u001b[39m_draw_disabled\u001b[39m\u001b[39m\"\u001b[39m, nullcontext)():\n\u001b[1;32m-> 2158\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m   2159\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2160\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[0;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 95\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[0;32m     97\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\figure.py:3154\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3151\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3154\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[0;32m   3155\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[0;32m   3157\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[0;32m   3158\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\axes\\_base.py:3070\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[39mif\u001b[39;00m artists_rasterized:\n\u001b[0;32m   3068\u001b[0m     _draw_rasterized(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[1;32m-> 3070\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[0;32m   3071\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[0;32m   3073\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   3074\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\axis.py:1394\u001b[0m, in \u001b[0;36mAxis.draw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1391\u001b[0m     tick\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m   1393\u001b[0m \u001b[39m# Shift label away from axes to avoid overlapping ticklabels.\u001b[39;00m\n\u001b[1;32m-> 1394\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_label_position(renderer)\n\u001b[0;32m   1395\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m   1397\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_offset_text_position(tlb1, tlb2)\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\axis.py:2368\u001b[0m, in \u001b[0;36mXAxis._update_label_position\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2364\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   2366\u001b[0m \u001b[39m# get bounding boxes for this axis and any siblings\u001b[39;00m\n\u001b[0;32m   2367\u001b[0m \u001b[39m# that have been set by `fig.align_xlabels()`\u001b[39;00m\n\u001b[1;32m-> 2368\u001b[0m bboxes, bboxes2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_tick_boxes_siblings(renderer\u001b[39m=\u001b[39;49mrenderer)\n\u001b[0;32m   2370\u001b[0m x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel\u001b[39m.\u001b[39mget_position()\n\u001b[0;32m   2371\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_position \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbottom\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\axis.py:2161\u001b[0m, in \u001b[0;36mAxis._get_tick_boxes_siblings\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2159\u001b[0m axis \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39m_axis_map[name]\n\u001b[0;32m   2160\u001b[0m ticks_to_draw \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 2161\u001b[0m tlb, tlb2 \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[0;32m   2162\u001b[0m bboxes\u001b[39m.\u001b[39mextend(tlb)\n\u001b[0;32m   2163\u001b[0m bboxes2\u001b[39m.\u001b[39mextend(tlb2)\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\axis.py:1317\u001b[0m, in \u001b[0;36mAxis._get_ticklabel_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[39mif\u001b[39;00m renderer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     renderer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39m_get_renderer()\n\u001b[0;32m   1315\u001b[0m \u001b[39mreturn\u001b[39;00m ([tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1316\u001b[0m          \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_visible()],\n\u001b[1;32m-> 1317\u001b[0m         [tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1318\u001b[0m          \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\axis.py:1317\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[39mif\u001b[39;00m renderer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     renderer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39m_get_renderer()\n\u001b[0;32m   1315\u001b[0m \u001b[39mreturn\u001b[39;00m ([tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1316\u001b[0m          \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_visible()],\n\u001b[1;32m-> 1317\u001b[0m         [tick\u001b[39m.\u001b[39;49mlabel2\u001b[39m.\u001b[39;49mget_window_extent(renderer)\n\u001b[0;32m   1318\u001b[0m          \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\text.py:943\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_text() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    942\u001b[0m     \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, dpi\u001b[39m=\u001b[39mdpi):\n\u001b[1;32m--> 943\u001b[0m         tx, ty \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_xy_display()\n\u001b[0;32m    944\u001b[0m         \u001b[39mreturn\u001b[39;00m Bbox\u001b[39m.\u001b[39mfrom_bounds(tx, ty, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m    946\u001b[0m \u001b[39mif\u001b[39;00m renderer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\text.py:244\u001b[0m, in \u001b[0;36mText._get_xy_display\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[39mGet the (possibly unit converted) transformed x, y in display coords.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    243\u001b[0m x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_unitless_position()\n\u001b[1;32m--> 244\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_transform()\u001b[39m.\u001b[39;49mtransform((x, y))\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\transforms.py:1495\u001b[0m, in \u001b[0;36mTransform.transform\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m   1492\u001b[0m values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_dims))\n\u001b[0;32m   1494\u001b[0m \u001b[39m# Transform the values\u001b[39;00m\n\u001b[1;32m-> 1495\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_affine(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_non_affine(values))\n\u001b[0;32m   1497\u001b[0m \u001b[39m# Convert the result back to the shape of the input values.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m ndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:297\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m     warn_deprecated(\n\u001b[0;32m    293\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mold\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m() \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhas been renamed \u001b[39m\u001b[39m{\u001b[39;00mnew\u001b[39m!r}\u001b[39;00m\u001b[39m since Matplotlib \u001b[39m\u001b[39m{\u001b[39;00msince\u001b[39m}\u001b[39;00m\u001b[39m; support \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    296\u001b[0m     kwargs[new] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(old)\n\u001b[1;32m--> 297\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\transforms.py:2409\u001b[0m, in \u001b[0;36mCompositeGenericTransform.transform_affine\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m   2406\u001b[0m \u001b[39m@_api\u001b[39m\u001b[39m.\u001b[39mrename_parameter(\u001b[39m\"\u001b[39m\u001b[39m3.8\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpoints\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2407\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform_affine\u001b[39m(\u001b[39mself\u001b[39m, values):\n\u001b[0;32m   2408\u001b[0m     \u001b[39m# docstring inherited\u001b[39;00m\n\u001b[1;32m-> 2409\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_affine()\u001b[39m.\u001b[39mtransform(values)\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\matplotlib\\transforms.py:2436\u001b[0m, in \u001b[0;36mCompositeGenericTransform.get_affine\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2434\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_b\u001b[39m.\u001b[39mget_affine()\n\u001b[0;32m   2435\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2436\u001b[0m     \u001b[39mreturn\u001b[39;00m Affine2D(np\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_b\u001b[39m.\u001b[39;49mget_affine()\u001b[39m.\u001b[39;49mget_matrix(),\n\u001b[0;32m   2437\u001b[0m                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_a\u001b[39m.\u001b[39;49mget_affine()\u001b[39m.\u001b[39;49mget_matrix()))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "X = dfm.todense()\n",
    "\n",
    "# Plot a heatmap of the dfm\n",
    "ax.imshow(\n",
    "    X,\n",
    "    cmap = \"Greys\",\n",
    "    norm = Normalize(vmin=0, vmax=3)\n",
    ")\n",
    "\n",
    "# Create a grid using minor ticks\n",
    "ax.set_xticks(np.arange(X.shape[1])+0.5, minor=True)\n",
    "ax.set_yticks(np.arange(X.shape[0])+0.5, minor=True)\n",
    "ax.grid(which=\"minor\", zorder=5)\n",
    "\n",
    "# Set up x labels\n",
    "ax.xaxis.tick_top()\n",
    "ax.set_xticks(np.arange(X.shape[1]))\n",
    "ax.set_xticklabels(vocab, rotation=60, ha=\"left\", va=\"bottom\")\n",
    "\n",
    "# Set up y labels\n",
    "ax.set_yticks(range(len(all_speeches)))\n",
    "ax.set_yticklabels(all_speeches)\n",
    "\n",
    "\n",
    "# Put the numbers in\n",
    "for m in range(X.shape[0]):\n",
    "    for n in range(X.shape[1]):\n",
    "        ax.text(n, m, X[m, n], ha=\"center\", va=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abgeordnet', 'absicht', 'act', 'adaquat', 'adjustment',\n",
       "       'afghanistan', 'allerding', 'allgemein', 'amt', 'anerkannt',\n",
       "       'angebotsseit', 'angeht', 'angekundigt', 'angeschaut', 'angesicht',\n",
       "       'anheiz', 'anja', 'anlass', 'anpass', 'anstreng', 'antwort',\n",
       "       'antwortzeit', 'appell', 'arbeit', 'arbeitseb', 'arbeitskraft',\n",
       "       'arbeitsmarkt', 'arbeitsmarktintegration', 'arbeitsmarktzugang',\n",
       "       'arbeitsplatz', 'armut', 'asylantrag',\n",
       "       'asylbewerberleistungsgesetz', 'asylpaket', 'asylverfahr',\n",
       "       'attraktiv', 'attraktivst', 'aufbau', 'auffass', 'aufnahm',\n",
       "       'augenmerk', 'ausfuhr', 'ausgabeobergrenz', 'ausgabeprogramm',\n",
       "       'ausgabeverhalt', 'ausgefuhrt', 'ausgelauf', 'ausgerechnet',\n",
       "       'ausgezahlt', 'auss', 'aussengrenz', 'ausserhalb', 'ausserst',\n",
       "       'ausstieg', 'austausch', 'austauschmechanism', 'auswart',\n",
       "       'auswert', 'auswirk', 'auszahl', 'auszuzahl', 'baldmog',\n",
       "       'bandbreit', 'baustein', 'beabsichtigt', 'beacht', 'beachtet',\n",
       "       'beck', 'bedank', 'bedarf', 'bedeutet', 'bedi', 'beeintrachtigt',\n",
       "       'beend', 'befasst', 'befriedigt', 'befristet', 'behg', 'behord',\n",
       "       'beid', 'beim', 'beiseit', 'beispiel', 'beispielsweis', 'bekampf',\n",
       "       'belast', 'belastungsfaktor', 'bemuh', 'berat', 'bereich',\n",
       "       'bereit', 'bereitet', 'bericht', 'berucksicht', 'berufsabschluss',\n",
       "       'beschaft', 'beschaftigt', 'beschleun', 'beschloss', 'beschluss',\n",
       "       'beseit', 'besetzt', 'besond', 'bess', 'besteh', 'beteiligt',\n",
       "       'betreff', 'bevolker', 'bevor', 'bezahl', 'bezieh', 'bezieht',\n",
       "       'bezog', 'bitt', 'bmas', 'bmf', 'bmfchristian', 'boehring', 'bord',\n",
       "       'bors', 'brandn', 'braucht', 'breit', 'brems',\n",
       "       'brennstoffemissionshandelsgesetz', 'bring', 'bringt', 'budgeti',\n",
       "       'bund', 'bundesfinanzminist', 'bundesfinanzministerium',\n",
       "       'bundesinnenministerin', 'bundesinnenministerium', 'bundeskanzl',\n",
       "       'bundesminist', 'bundesministerin', 'bundesregier', 'bundestag',\n",
       "       'bundnis', 'burg', 'burgergeld', 'burgerinn', 'burokrati', 'bzw',\n",
       "       'capital', 'carbon', 'charakterisiert',\n",
       "       'christianlindnerbundesminist', 'dabei', 'dadurch', 'dafur',\n",
       "       'dageg', 'dam', 'damal', 'dampf', 'dampfung', 'daneb', 'dank',\n",
       "       'dankenswerterweis', 'daran', 'darauf', 'darf', 'dargestellt',\n",
       "       'darstell', 'darub', 'dauerhaft', 'davon', 'debatt', 'deckung',\n",
       "       'definitiv', 'defizit', 'denk', 'denkbar', 'dennoch', 'der',\n",
       "       'deshalb', 'deutlich', 'deutsch', 'deutschland', 'diaby', 'diejen',\n",
       "       'dien', 'diesbezug', 'differenzi', 'ding', 'direkt', 'drei',\n",
       "       'dritt', 'durchgesetzt', 'durchsetz', 'durf', 'eben', 'ebenfall',\n",
       "       'eher', 'eigenkapitalbasis', 'eigenmittel', 'einblick',\n",
       "       'eingebund', 'eingefuhrt', 'eingespr', 'eingetret', 'einkomm',\n",
       "       'einleit', 'einnahm', 'einstieg', 'eint', 'einverstandnis',\n",
       "       'einwander', 'einzeln', 'elektron', 'element', 'end', 'endlich',\n",
       "       'energieerzeug', 'energiepolit', 'engagement', 'entfall',\n",
       "       'entfernungspauschal', 'enthalt', 'entlast', 'entlastet',\n",
       "       'entlastungsmassnahm', 'entscheid', 'entschied', 'entschloss',\n",
       "       'entschuld', 'entsprech', 'entwickl', 'erfahr', 'erfolg', 'erford',\n",
       "       'erfull', 'ergeb', 'ergebnis', 'erhoh', 'erhoht', 'erinn',\n",
       "       'erinner', 'erlaub', 'erleichter', 'ernahrungssicher', 'ernst',\n",
       "       'erreich', 'erreicht', 'erschw', 'ersetz', 'erst', 'erstmal',\n",
       "       'erteilt', 'erwag', 'erwahn', 'etabliert', 'etat', 'etwa', 'eu',\n",
       "       'euro', 'europa', 'evaluiert', 'exemplar', 'expertis',\n",
       "       'exportorientiert', 'exzellent', 'fachlich', 'faes', 'fahrplan',\n",
       "       'faktor', 'fall', 'falsch', 'famili', 'federfuhr', 'fehl',\n",
       "       'fernwarm', 'festhalt', 'finanz', 'finanzenbundesminist',\n",
       "       'finanzi', 'finanzier', 'finanzierungsbedarf',\n",
       "       'finanzierungsbedurfnis', 'finanzierungsmog', 'finanzminist',\n",
       "       'finanzministerium', 'finanzplanungszeitraum', 'finanzrahm',\n",
       "       'find', 'findet', 'fiskal', 'fixier', 'flexibl', 'flucht',\n",
       "       'flussiggasterminal', 'fond', 'fondsgesellschaft', 'fondsstandort',\n",
       "       'food', 'forschungsforder', 'fortgesetzt', 'fortschritt',\n",
       "       'fortwahr', 'fortzusetz', 'frag', 'fragestell', 'fragestellerinn',\n",
       "       'fragezeit', 'fragmentiert', 'fraktion', 'franziska', 'franzos',\n",
       "       'frau', 'freizug', 'fruh', 'fug', 'fuhr', 'fuhrungskraft', 'gab',\n",
       "       'ganz', 'gar', 'gas', 'gaspreisbrems', 'gastronomi', 'gebracht',\n",
       "       'geehrt', 'gefluchtet', 'gefragt', 'gefreut', 'gefuhrt',\n",
       "       'gegenfinanzier', 'gegenteil', 'gegenub', 'gegenwart', 'geh',\n",
       "       'gehalt', 'geht', 'geklart', 'gekomm', 'geld', 'geling', 'gelingt',\n",
       "       'gelung', 'gemacht', 'gemeinsam', 'gemeinschaft', 'genannt',\n",
       "       'genehmigungsverfahr', 'generation', 'genes', 'genug', 'geplant',\n",
       "       'gerad', 'gerecht', 'gerichtet', 'gerieb', 'gesagt', 'gesamtstaat',\n",
       "       'geschaftsbereich', 'geschutzt', 'geseh', 'gesenkt',\n",
       "       'gesetzentwurf', 'gesetzgeb', 'gesetzgebungsvorhab', 'gesprach',\n",
       "       'gesproch', 'gestalt', 'getroff', 'geubt', 'gewahrt', 'gewinn',\n",
       "       'gezog', 'gibt', 'ging', 'glas', 'glaub', 'glaubwurd',\n",
       "       'gleichzeit', 'gluck', 'gottschalk', 'grassl', 'grenznah',\n",
       "       'grenzuberschreit', 'grob', 'gross', 'grossenordn', 'grosst',\n",
       "       'grun', 'grund', 'grundfreibetrag', 'grundgesetz', 'grundleg',\n",
       "       'grundsatz', 'grupp', 'gut', 'halt', 'haltung',\n",
       "       'hauptfragestellerin', 'haushalt', 'haushaltsausschuss',\n",
       "       'haushaltsentwurf', 'haushaltsfuhr', 'haushaltsgesetzgeb',\n",
       "       'heisst', 'heizung', 'hemmt', 'henneberg', 'herkunftsland', 'herr',\n",
       "       'herrn', 'herzlich', 'heut', 'hierbei', 'hinaus', 'hingewies',\n",
       "       'hinweis', 'hinzu', 'hoch', 'hochinnovativ', 'hoff', 'hoffnung',\n",
       "       'hoh', 'hoppermann', 'hurd', 'ide', 'illegal', 'imm', 'ina',\n",
       "       'inflation', 'inflationsausgleichsgesetz', 'inflationsentwickl',\n",
       "       'inflationsprami', 'inhalt', 'innenministerin', 'innerhalb',\n",
       "       'innovativ', 'insbesond', 'insgesamt', 'insof', 'intensiv',\n",
       "       'international', 'investi', 'investition', 'investitionskapital',\n",
       "       'inwieweit', 'ja', 'jahr', 'jan', 'jedenfall', 'jetzig', 'jeweil',\n",
       "       'jung', 'kabinettssitz', 'kapital', 'kapitalmarkt',\n",
       "       'kapitalmarktunion', 'kapitalmarktzugang', 'karamba', 'katharina',\n",
       "       'kathrin', 'kaufkraft', 'kaufkraftverlust', 'kay', 'keinerlei',\n",
       "       'kenn', 'kernelement', 'kernenergi', 'kernhaushalt',\n",
       "       'kernkraftwerk', 'kfw', 'kind', 'kindergeld', 'klein', 'klimageld',\n",
       "       'klussendorf', 'koalition', 'kohl', 'kolleg', 'kollegin',\n",
       "       'kolleginn', 'komm', 'kommt', 'kompetenziell', 'komplett',\n",
       "       'konjunkturell', 'konkret', 'konnt', 'kontext', 'kontroll',\n",
       "       'kontrollein', 'kopf', 'kost', 'kostet', 'kraft', 'kris',\n",
       "       'krisenbedingt', 'kritisch', 'ktf', 'kurz', 'kurzfrist', 'lag',\n",
       "       'land', 'lang', 'latendorf', 'laufzeit', 'leg', 'legislaturperiod',\n",
       "       'leid', 'leistung', 'leistungsfah', 'letzt', 'ley', 'lieb',\n",
       "       'liegt', 'lindn', 'link', 'lohn', 'los', 'luck', 'macht',\n",
       "       'magdeburg', 'mal', 'management', 'mangel', 'market', 'massnahm',\n",
       "       'mathias', 'mechanism', 'mechanismus', 'mehr', 'mehrfach',\n",
       "       'mehrjahr', 'mehrwertsteu', 'mehrwertsteuersatz', 'mensch',\n",
       "       'metaeb', 'middelberg', 'migration', 'migrationszahl', 'milliard',\n",
       "       'million', 'mitarbeiterkapitalbeteil', 'miteinand', 'miteinbezog',\n",
       "       'mitgliedstaat', 'mittel', 'mitunterstutz', 'mobilisi', 'mocht',\n",
       "       'moglich', 'moment', 'monat', 'muss', 'nach', 'nachfrag',\n",
       "       'nachfragewunsch', 'nachgesteuert', 'nachhaltigkeitsziel',\n",
       "       'nachteil', 'nahrungsmittelmarkt', 'namlich', 'nancy', 'national',\n",
       "       'natur', 'nehm', 'nein', 'nenn', 'neu', 'next', 'nie', 'niedrig',\n",
       "       'notwend', 'notzeit', 'nutzung', 'obliegt', 'obwohl', 'offensicht',\n",
       "       'offent', 'oft', 'okonom', 'oktob', 'operativ', 'option', 'ossn',\n",
       "       'paradigmenwechsel', 'paradox', 'partn', 'pet', 'pilotprojekt',\n",
       "       'pipelineversorg', 'plan', 'polit', 'positiv', 'potenzial',\n",
       "       'prasidentin', 'praxis', 'preis', 'preisbrems', 'preisentwickl',\n",
       "       'preispfad', 'preisspitz', 'priorisi', 'privat', 'pro', 'probl',\n",
       "       'problem', 'profitiert', 'prognostiziert', 'programm', 'protokoll',\n",
       "       'prozent', 'pruf', 'pruft', 'punkt', 'qualifikationsdefizit',\n",
       "       'qualifiziert', 'quell', 'rahm', 'rahmenbeding', 'rasch', 'rat',\n",
       "       'rating', 'raum', 'reagi', 'rechn', 'rechnungsleg', 'recht',\n",
       "       'rechtsprech', 'red', 'reduction', 'reduzier', 'reduziert',\n",
       "       'refinanzi', 'regelsatz', 'regier', 'regierungsentwurf',\n",
       "       'regierungserklar', 'rekordinvestition', 'rekordniveau',\n",
       "       'rekordzeit', 'respekt', 'ressort', 'ressortabstimm',\n",
       "       'ressortprinzip', 'reviews', 'richtig', 'roadmap', 'ruckgriff',\n",
       "       'ruckversicher', 'rudolph', 'ruinos', 'sag', 'sagt', 'salz',\n",
       "       'schaff', 'schau', 'schichtungsfrei', 'schlepperkriminalitat',\n",
       "       'schliess', 'schlimm', 'schluss', 'schmidt', 'schnell',\n",
       "       'schnellstmog', 'schon', 'schuldenbrems', 'schuldenfinanziert',\n",
       "       'schulz', 'schutz', 'schwerpunkt', 'schwerwieg', 'seh', 'sei',\n",
       "       'seinerzeit', 'seit', 'sektor', 'sekund', 'senk', 'setz', 'setzt',\n",
       "       'shock', 'sicherzustell', 'sinkt', 'sinn', 'situation', 'sitz',\n",
       "       'sitzungswoch', 'skeptisch', 'sodass', 'sofort', 'sogenannt',\n",
       "       'solidaritat', 'sollt', 'sondervermog', 'sorg', 'sowi', 'sozial',\n",
       "       'spass', 'speisegastronomi', 'spekulationsfrist', 'spending',\n",
       "       'sprachdefizit', 'staat', 'staatsdefizit', 'staatsschuldenquot',\n",
       "       'standort', 'standortnachteil', 'stark', 'stationar', 'statist',\n",
       "       'steh', 'steht', 'steig', 'steiger', 'steigt', 'stell', 'stellt',\n",
       "       'stellung', 'step', 'steu', 'steuerfrei', 'steuerrecht',\n",
       "       'steuerschatz', 'strategi', 'streckenweis', 'strom', 'strukturell',\n",
       "       'studienkredit', 'studium', 'subvention', 'svenja', 'syri',\n",
       "       'szenari', 'tag', 'talent', 'tarifentwickl', 'tatsach',\n",
       "       'technisch', 'technologi', 'teil', 'thema', 'tim', 'tisch', 'trag',\n",
       "       'treff', 'trendwend', 'trenn', 'trotz', 'tun', 'uberbord',\n",
       "       'uberwund', 'uberzog', 'ubrig', 'ukrain', 'umsatzsteu',\n",
       "       'umsatzsteuerbetrug', 'umstell', 'umzugeh', 'unabhang',\n",
       "       'unakzeptabel', 'unaufmerksam', 'unbefried', 'ungenutzt',\n",
       "       'unglaub', 'union', 'unmittelbar', 'uns', 'unterblieb',\n",
       "       'unterbreitet', 'unterhalb', 'unternehm', 'unternehmensteu',\n",
       "       'unternimmt', 'unterschied', 'unterstutz', 'unterstutzt',\n",
       "       'unverandert', 'unverantwortbar', 'ursprung', 'usa', 'verabred',\n",
       "       'verandert', 'veranschlag', 'verantwort', 'verantwortbar',\n",
       "       'verbess', 'verbind', 'verbrennungsmotor', 'verbund', 'vereinfach',\n",
       "       'vereinigt', 'verfahr', 'verfug', 'vergang', 'vergleich',\n",
       "       'verkauf', 'verkehrsweg', 'verlager', 'verlangert', 'verli',\n",
       "       'verlor', 'verlustverrechnungskreis', 'verschiedent', 'versorg',\n",
       "       'verstark', 'versteuernd', 'versteuert', 'vervollkommn', 'verwalt',\n",
       "       'verwaltungsratsvorsitz', 'verweis', 'verwirklich', 'verzicht',\n",
       "       'viel', 'vierkopf', 'volkmar', 'vollig', 'vollumfang',\n",
       "       'vollzugsbeamt', 'vollzugsbeamtinn', 'voneinand', 'vorangegang',\n",
       "       'vorangeschickt', 'voraus', 'voraussetz', 'vorbereitet', 'vorgab',\n",
       "       'vorgangerregier', 'vorgegeb', 'vorgelegt', 'vorgeschlag',\n",
       "       'vorgeseh', 'vorhergeseh', 'vorkrisenniveau', 'vorleg', 'vorlieg',\n",
       "       'vorschlag', 'vorsorg', 'vorzuwerf', 'wachstum',\n",
       "       'wachstumschancengesetz', 'wachstumsunternehm', 'wahlperiod',\n",
       "       'wahrungsfond', 'wand', 'war', 'warenkorb', 'wart', 'weg', 'weis',\n",
       "       'weit', 'weiterentwickeln', 'weiterhin', 'weiterverfolgt', 'wenig',\n",
       "       'wenzel', 'werk', 'wertpapi', 'wertschopf', 'wettbewerbsfah',\n",
       "       'wettbewerbsnachteil', 'wichtig', 'window', 'wirk', 'wirtschaft',\n",
       "       'wirtschaftsleb', 'wirtschaftsorientiert',\n",
       "       'wirtschaftsstabilisierungsfond', 'wiss', 'woch', 'word', 'wort',\n",
       "       'worub', 'wund', 'zahlt', 'zeig', 'zeit', 'zeitpunkt',\n",
       "       'zentralbank', 'zieh', 'ziel', 'zins', 'zinsentwickl', 'zoll',\n",
       "       'zud', 'zug', 'zugang', 'zugegriff', 'zugeordnet', 'zugleich',\n",
       "       'zukunft', 'zukunftsfinanzierungsgesetz', 'zuletzt', 'zunach',\n",
       "       'zuruck', 'zuruckgefuhrt', 'zusamm', 'zusammenarbeit',\n",
       "       'zusammenhang', 'zusatz', 'zustand', 'zustimm', 'zuversicht',\n",
       "       'zweck', 'zwei', 'zweit', 'zwischenzeit'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kaius\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'stop_words' parameter of CountVectorizer must be a str among {'english'}, an instance of 'list' or None. Got 'german' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kaius\\OneDrive - Hertie School\\MSc Data Science for Public Policy\\Semester_3\\Text as Data\\assignments\\TaD-programming-excercises\\assignment2.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaius/OneDrive%20-%20Hertie%20School/MSc%20Data%20Science%20for%20Public%20Policy/Semester_3/Text%20as%20Data/assignments/TaD-programming-excercises/assignment2.ipynb#X33sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [porter\u001b[39m.\u001b[39mstem(word) \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m word_tokenize(text)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaius/OneDrive%20-%20Hertie%20School/MSc%20Data%20Science%20for%20Public%20Policy/Semester_3/Text%20as%20Data/assignments/TaD-programming-excercises/assignment2.ipynb#X33sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m vectorizer \u001b[39m=\u001b[39m CountVectorizer(stop_words\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgerman\u001b[39m\u001b[39m\"\u001b[39m, tokenizer\u001b[39m=\u001b[39m porter_tokenizer)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kaius/OneDrive%20-%20Hertie%20School/MSc%20Data%20Science%20for%20Public%20Policy/Semester_3/Text%20as%20Data/assignments/TaD-programming-excercises/assignment2.ipynb#X33sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m dfm \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39;49mfit_transform(all_speeches)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaius/OneDrive%20-%20Hertie%20School/MSc%20Data%20Science%20for%20Public%20Policy/Semester_3/Text%20as%20Data/assignments/TaD-programming-excercises/assignment2.ipynb#X33sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m vocab \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mget_feature_names_out()\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\sklearn\\base.py:1145\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m partial_fit_and_fitted \u001b[39m=\u001b[39m (\n\u001b[0;32m   1141\u001b[0m     fit_method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpartial_fit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1142\u001b[0m )\n\u001b[0;32m   1144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m global_skip_validation \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1145\u001b[0m     estimator\u001b[39m.\u001b[39;49m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[0;32m   1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\sklearn\\base.py:638\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    631\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \n\u001b[0;32m    633\u001b[0m \u001b[39m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[39m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m     validate_parameter_constraints(\n\u001b[0;32m    639\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parameter_constraints,\n\u001b[0;32m    640\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    641\u001b[0m         caller_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[0;32m    642\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m     )\n\u001b[1;32m---> 95\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     96\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'stop_words' parameter of CountVectorizer must be a str among {'english'}, an instance of 'list' or None. Got 'german' instead."
     ]
    }
   ],
   "source": [
    "# 2.3 Process the list of speeches into a TFIDF matrix. What are the highest scoring terms in this matrix for the\n",
    "# first speech by the politician you have chosen?\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "lindner_speeches = lindner_speech['Speech']\n",
    "all_speeches = ' '.join([p for p in lindner_speeches])\n",
    "\n",
    "\n",
    "def porter_tokenizer(text):\n",
    "    porter = PorterStemmer()\n",
    "    return [porter.stem(word) for word in word_tokenize(text)]\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words= \"german\", tokenizer= porter_tokenizer)\n",
    "dfm = vectorizer.fit_transform(all_speeches)\n",
    "vocab = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kaius\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kaius\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kaius\\OneDrive - Hertie School\\MSc Data Science for Public Policy\\Semester_3\\Text as Data\\assignments\\TaD-programming-excercises\\assignment2.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaius/OneDrive%20-%20Hertie%20School/MSc%20Data%20Science%20for%20Public%20Policy/Semester_3/Text%20as%20Data/assignments/TaD-programming-excercises/assignment2.ipynb#X40sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Compute TF-IDF\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaius/OneDrive%20-%20Hertie%20School/MSc%20Data%20Science%20for%20Public%20Policy/Semester_3/Text%20as%20Data/assignments/TaD-programming-excercises/assignment2.ipynb#X40sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m vectorizer \u001b[39m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kaius/OneDrive%20-%20Hertie%20School/MSc%20Data%20Science%20for%20Public%20Policy/Semester_3/Text%20as%20Data/assignments/TaD-programming-excercises/assignment2.ipynb#X40sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m dfm\u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39;49mfit_transform(processed_texts)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaius/OneDrive%20-%20Hertie%20School/MSc%20Data%20Science%20for%20Public%20Policy/Semester_3/Text%20as%20Data/assignments/TaD-programming-excercises/assignment2.ipynb#X40sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m vocab \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mget_feature_names_out()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kaius/OneDrive%20-%20Hertie%20School/MSc%20Data%20Science%20for%20Public%20Policy/Semester_3/Text%20as%20Data/assignments/TaD-programming-excercises/assignment2.ipynb#X40sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Extract top features based on tf-idf scores\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2139\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params()\n\u001b[0;32m   2133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf \u001b[39m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2134\u001b[0m     norm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm,\n\u001b[0;32m   2135\u001b[0m     use_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_idf,\n\u001b[0;32m   2136\u001b[0m     smooth_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmooth_idf,\n\u001b[0;32m   2137\u001b[0m     sublinear_tf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msublinear_tf,\n\u001b[0;32m   2138\u001b[0m )\n\u001b[1;32m-> 2139\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[0;32m   2140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m   2141\u001b[0m \u001b[39m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2142\u001b[0m \u001b[39m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1389\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1381\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1382\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1386\u001b[0m             )\n\u001b[0;32m   1387\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1389\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1391\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1392\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kaius\\.virtualenvs\\TaD-programming-excercises-FCqiZMWn\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1295\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1293\u001b[0m     vocabulary \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1294\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1295\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1296\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1297\u001b[0m         )\n\u001b[0;32m   1299\u001b[0m \u001b[39mif\u001b[39;00m indptr[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m np\u001b[39m.\u001b[39miinfo(np\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax:  \u001b[39m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1300\u001b[0m     \u001b[39mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import GermanStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Assuming svenja_speech is your DataFrame\n",
    "#speech_list = lindner_speech['Speech'].tolist()\n",
    "\n",
    "# Load German stop words\n",
    "german_stop_words = set(stopwords.words('german'))\n",
    "\n",
    "# Initialize German stemmer\n",
    "stemmer = GermanStemmer()\n",
    "\n",
    "# Define a function for preprocessing\n",
    "def preprocess(text):\n",
    "    # Tokenize and remove punctuation\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    \n",
    "    # Remove stop words and perform stemming\n",
    "    return ' '.join(stemmer.stem(word) for word in words if word.lower() not in german_stop_words)\n",
    "\n",
    "# Preprocess the text\n",
    "processed_texts = [preprocess(text) for text in speech_list]\n",
    "\n",
    "# Compute TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "dfm= vectorizer.fit_transform(processed_texts)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Extract top features based on tf-idf scores\n",
    "features = vectorizer.get_feature_names_out()\n",
    "sums = dfm.sum(axis=0)\n",
    "\n",
    "# Create a dictionary with features and their corresponding tf-idf scores\n",
    "data = []\n",
    "for col, term in enumerate(features):\n",
    "    data.append((term, sums[0, col]))\n",
    "\n",
    "ranking = pd.DataFrame(data, columns=['term', 'rank'])\n",
    "sorted_ranking = ranking.sort_values('rank', ascending=False)\n",
    "\n",
    "# Display top 11 features\n",
    "print(sorted_ranking.head(11))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TaD-programming-excercise1-3c7Qo_HW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
